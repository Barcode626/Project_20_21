{"nbformat":4,"nbformat_minor":5,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"},"colab":{"name":"4_Merge Geo.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"accelerator":"TPU"},"cells":[{"cell_type":"code","metadata":{"id":"8199a3ab","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630327741164,"user_tz":-480,"elapsed":423,"user":{"displayName":"C XXX","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi80UhcWrrQsYptKdXzHpzrVRaRJG6wsKSZq7pO=s64","userId":"16747379684365591919"}},"outputId":"4809cad4-a56a-42b2-ca69-5d2e4cfe0c8d"},"source":["import pandas as pd\n","import csv\n","import os\n","import numpy as np\n","import re\n","import shutil\n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n","os.chdir(\"/content/drive/MyDrive/Data/csv/\")"],"id":"8199a3ab","execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1b24e23e"},"source":["def extract_hashtags(raw_hg):\n","    if raw_hg == '[]':\n","        return np.nan\n","    else:\n","        raw_hg = eval(raw_hg)\n","        hg_lst = []\n","        for i in raw_hg:\n","            hg_lst.append(i['text'])\n","        return hg_lst"],"id":"1b24e23e","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CAsVpgWKDTEG"},"source":["Mondt = {\"02\":29, \"03\":31, \"04\":30, \"05\":1}\n","path_txt = \"/content/drive/MyDrive/Data/txt/\"\n","path = \"/content/drive/MyDrive/Data/\"\n","\n","count_all = 0\n","for key, value in Mondt.items():\n","    for day_i in range(1, value+1):\n","        if day_i < 10:\n","            day_j = '0' + f'{day_i}'\n","        else:\n","            day_j = f'{day_i}'\n","\n","        f_name = 'geo_2020-'+ key + '-' + day_j\n","\n","        df = pd.read_csv('hy_' + f_name + '.csv', header=None, dtype = str, encoding='utf-8-sig', engine='python')\n","        df.columns = ['created_at', 'id', 'full_text', 'hashtags', \\\n","                                'location', 'geo', 'coordinates', 'place', \\\n","                                'retweet_count', 'favorite_count', 'language']\n","\n","        # extract the colomns: \n","        #'created_at', 'id', 'full_text', 'hashtags', \n","        #'retweet_count', 'favorite_count', 'language'\n","        df1 = df.iloc[:, [0, 1, 2, 3, 8, 9, 10]].copy() \n","        df1['date'] = pd.to_datetime(df1.iloc[:, 0]).dt.date\n","\n","        #set 'date' to the first place\n","        df2 = df1.iloc[:, [7, 1, 2, 3, 4, 5, 6]].copy() # resort the colomns\n","        df3 = df2.drop_duplicates(subset='id', keep=\"first\")\n","\n","        df4 = df3[df3['language'] == 'en'].copy()\n","        df4['hashtags'] = df4['hashtags'].apply(extract_hashtags)\n","\n","        df5 = df4.iloc[:, [0, 1, 2, 3, 4, 5]].copy()\n","        df5.reset_index(drop=True, inplace=True)\n","        df5['id'] = df5['id'].apply(str)\n","        df5['id'] = df5['id'].apply(lambda r: r.strip())\n","\n","        geo = pd.read_csv(path_txt + f_name +'.txt', sep='\\n', header=None, dtype=str)\n","        geo['sp_txt'] = geo[0].str.replace(',', '\\\\', n = 1)\n","        geo[['id', 'geography']] = geo['sp_txt'].str.split('\\\\', expand=True)                              \n","\n","        sp_geo = geo.iloc[:, [2,3]].copy()\n","        sp_geo['id'] = sp_geo['id'].apply(str)\n","        sp_geo.reset_index(drop=True, inplace=True)\n","        sp_geo['id'] = sp_geo['id'].apply(lambda r: r.strip())\n","\n","        combine_csv = pd.merge(df5, sp_geo, on=['id'], how='left')\n","\n","        combine_csv.to_csv('all_gb.csv', mode='a', header=None, index=False, encoding='utf-8-sig')\n","\n","        count_all = count_all + combine_csv.shape[0]\n","shutil.move('all_gb.csv', path + 'all_gb.csv')\n","print(f'The total number of tweets from country code gb is {count_all}')"],"id":"CAsVpgWKDTEG","execution_count":null,"outputs":[]}]}