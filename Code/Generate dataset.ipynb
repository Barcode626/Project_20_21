{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"8_Generate dataset.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","authorship_tag":"ABX9TyNSegHZkwqEtENs/GCGcltu"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"8UXF2AaurX4n"},"source":["import os\n","import numpy as np\n","import pandas as pd\n","import csv\n","import time\n","import shutil\n","\n","# Gensim\n","import gensim\n","from gensim.utils import simple_preprocess\n","from gensim.parsing.preprocessing import STOPWORDS\n","from nltk.stem import WordNetLemmatizer\n","from nltk.stem.porter import * \n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n","os.chdir(\"/content/drive/MyDrive/Code\")\n","import cleaning_tweets as ct\n","os.chdir(\"/content/drive/MyDrive/Data\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9y7yHDjfPYpe"},"source":["Set text_id to the whole cleaned data set"]},{"cell_type":"code","metadata":{"id":"3aEOoMn5z1T4"},"source":["df_clean = pd.read_csv('cleaned_data.csv', header=None, dtype=str, encoding='utf-8-sig', engine='python')\n","df_clean.columns = ['date', 'id', 'text', 'hashtags', \\\n","                                    'state', 'county and city',\\\n","                                    'retweet_count', 'favorite_count']\n","\n","df_id = pd.read_csv('textid.csv', header=None, dtype=str, encoding='utf-8-sig', engine='python')\n","df_id.columns = [\"text\", \"text_id\"]\n","\n","df = pd.merge(df_clean, df_id, on='text', how=\"left\")\n","df.dropna(subset=['text_id'], axis=0, how='any', inplace=True)\n","df.dropna(subset=['text'], axis=0, how='any', inplace=True)\n","df.drop_duplicates(['id'], keep='first', ignore_index=True, inplace=True)\n","df.reset_index(inplace=True, drop=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SeOuyESKPqEO"},"source":["Assign sentiment labels and LDA results to cleaned data."]},{"cell_type":"code","metadata":{"id":"o5jGRtli-4WL"},"source":["df_st =  pd.read_csv('textid_st.csv', header = None, dtype = str, encoding = 'utf-8-sig', engine='python')\n","df_st.columns = [\"text\", \"text_id\", \"st_labels\", \"st_scores\"]\n","df_ap  = pd.read_csv('textid_ap.csv', header = None, dtype = str, encoding = 'utf-8-sig', engine='python')\n","df_ap.columns = [\"text_id\", \"aspects\"]\n","\n","df_text = pd.merge(df_st, df_ap, on='text_id', how='left')\n","df_text.dropna(subset=['text_id'], axis=0, how='any', inplace=True)\n","\n","tlst = list(df_text['text'].astype(str))\n","df_text.drop(labels=['text'], axis=1, inplace=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1xuqN36wvhWT"},"source":["new = pd.merge(df, df_text, on='text_id', how='left')\n","new.dropna(subset=['text_id'], axis=0, how='any', inplace=True)\n","new.drop_duplicates(['id'], keep='first', ignore_index=True, inplace=True)\n","new.reset_index(inplace=True, drop=True)\n","# new.to_csv('data_with_labels.csv', mode='a', header=None, index=False, encoding = 'utf-8-sig')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GGyQTf_5FbB4","executionInfo":{"status":"ok","timestamp":1630866440097,"user_tz":-480,"elapsed":5181,"user":{"displayName":"C XXX","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi80UhcWrrQsYptKdXzHpzrVRaRJG6wsKSZq7pO=s64","userId":"16747379684365591919"}},"outputId":"112026d5-9b70-4d01-d7a1-afa31a86e7e1"},"source":["df1 = new.copy()\n","df1.drop_duplicates(['text_id'], keep='first', ignore_index=True, inplace=True)\n","# remove tweets with empy value of \"aspects\"\n","df2 = df1.dropna(subset=['aspects'], axis=0, how='any').copy()\n","# df2.to_csv(\"data_with_labels_mini.csv\", mode='a', index=False, header=None, encoding = 'utf-8-sig')\n","df2.info()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'pandas.core.frame.DataFrame'>\n","Int64Index: 4519697 entries, 0 to 4584928\n","Data columns (total 12 columns):\n"," #   Column           Dtype \n","---  ------           ----- \n"," 0   date             object\n"," 1   id               object\n"," 2   text             object\n"," 3   hashtags         object\n"," 4   state            object\n"," 5   county and city  object\n"," 6   retweet_count    object\n"," 7   favorite_count   object\n"," 8   text_id          object\n"," 9   st_labels        object\n"," 10  st_scores        object\n"," 11  aspects          object\n","dtypes: object(12)\n","memory usage: 448.3+ MB\n"]}]},{"cell_type":"markdown","metadata":{"id":"BkWeHr33DlUZ"},"source":["Extract aspects"]},{"cell_type":"code","metadata":{"id":"9JSeF-8u1CMo"},"source":["df2 = pd.read_csv('data_with_labels_mini.csv', header=None, dtype=str, encoding='utf-8-sig', engine='python')\n","df2.columns = ['date', 'id', 'text', 'hashtags', \\\n","                            'state', 'county and city',\\\n","                            'retweet_count', 'favorite_count',\\\n","                            'text_id', 'st_labels', 'st_scores', 'aspects']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cUJYoVUUEO28"},"source":["# 4m data\n","topicidx_to_aspect, aspect_to_idx, idx_to_aspect = ct.getidx()\n","\n","for idx, ap in idx_to_aspect.items():\n","    df2.loc[:, ap] = df2[\"aspects\"].apply(lambda r: ct.dva(r, int(idx))[0])\n","    df2.loc[:, ap+'_score'] = df2[\"aspects\"].apply(lambda r: ct.dva(r, int(idx))[1])\n","\n","i = 0\n","for j in range(len(idx_to_aspect)):\n","    df_ap = df2.iloc[:, [0, 1, 2, 3, 4, 5, 8, 9, 10, 12+i, 13+i]].copy()\n","    ap_name = str(idx_to_aspect[str(j)])\n","    df_ap.dropna(subset=[ap_name], axis=0, how='any', inplace=True)\n","    df_ap.rename(columns={ap_name: 'aspects', ap_name+'_score': 'ap_scores'}, inplace=True)\n","    df_ap.loc[:, 'aspects_idx'] = [str(j)]*df_ap.shape[0]\n","    df_ap.reset_index(drop=True, inplace=True)\n","\n","    df_ap.to_csv(\"ap_textid_mini_new.csv\", header = None, mode='a', index=False, encoding = 'utf-8-sig')\n","    i += 2"],"execution_count":null,"outputs":[]}]}