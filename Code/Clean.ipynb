{"nbformat":4,"nbformat_minor":5,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"},"colab":{"name":"5_Clean.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"accelerator":"TPU"},"cells":[{"cell_type":"code","metadata":{"id":"18fc6b5b","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630328189524,"user_tz":-480,"elapsed":463,"user":{"displayName":"C XXX","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi80UhcWrrQsYptKdXzHpzrVRaRJG6wsKSZq7pO=s64","userId":"16747379684365591919"}},"outputId":"86f6cb8e-fe62-4973-e200-d38cf84a7125"},"source":["import re\n","import pandas as pd\n","import csv\n","import os\n","import numpy as np\n","import time\n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n","os.chdir(\"/content/drive/MyDrive/Code\")\n","import cleaning_tweets as ct\n","os.chdir(\"/content/drive/MyDrive/Data\")"],"id":"18fc6b5b","execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5b6344ce"},"source":["def clean_csv(df):\n","    # Hashtags\n","    ## clean hashtags\n","    df['hashtags'] = df['hashtags'].apply(ct.clean_hashtags)\n","    \n","    # Geography\n","    ## remove empty geography\n","    df.dropna(subset=['geography'], axis=0, how='any', inplace=True)\n","\n","    ## divide the geography into 'country_code' ,'state', 'county' and 'city'\n","    gg_cols = ['state', 'county', 'city']\n","    for gg_value in gg_cols:\n","        df.loc[:, gg_value] = df['geography'].apply(lambda r: ct.clean_geography(r, gg_value))\n","    \n","    ## drop nan value and combine\n","    df.dropna(subset=['county', 'city'], axis=0, how='all', inplace=True)\n","    df.loc[:, 'county and city'] = df.apply(lambda r: r['county'] if pd.isna(r['county'])==False else r['city'], axis=1)\n","    df.reset_index(inplace=True, drop=True)\n","\n","    # Full_text\n","    ## clean tweets\n","    df.loc[:, 'clean_text'] = df['full_text'].apply(ct.clean_tweets)\n","    \n","    df.drop(['full_text', 'geography', 'county', 'city'], axis=1, inplace=True)\n","    df.drop_duplicates(subset=['id'], keep='first', inplace=True)\n","    \n","    df1 = df.iloc[:, [0, 1, 7, 2, 5, 6, 3, 4]].copy()\n","    df1['id'] = df1['id'].apply(str)\n","    df1.dropna(subset=['clean_text'], axis=0, how='any', inplace=True)\n","    \n","    return df1"],"id":"5b6344ce","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"c9be5498"},"source":["df_chunk = pd.read_csv('all_gb.csv', header = None, dtype = str, \\\n","                                            chunksize=300000, encoding='utf-8-sig', engine='python')\n","count = 0\n","for chunk in df_chunk:\n","    start_time = time.time()\n","    chunk.columns = ['date', 'id', 'full_text', 'hashtags', \\\n","                                    'retweet_count', 'favorite_count', 'geography']\n","    chunk_new = clean_csv(chunk)\n","    chunk_new.to_csv('cleaned_data.csv', mode='a', header=None, index=False, encoding='utf-8-sig')\n","    print(f\"Done: {count} \\n time: {(time.time() - start_time)//60} minutes\")\n","    count += 1"],"id":"c9be5498","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"81fNYbg_QgmA"},"source":["Generate unique text with text_id"],"id":"81fNYbg_QgmA"},{"cell_type":"code","metadata":{"id":"Ba24GBRbJKKJ"},"source":["df = pd.read_csv('cleaned_data.csv', header = None, dtype = str, encoding = 'utf-8-sig')\n","df.columns = ['date', 'id', 'clean_text', 'hashtags', \\\n","                        'state', 'county and city',\\\n","                        'retweet_count', 'favorite_count']\n","print(f\"df has {df.shape[0]} rows\")\n","\n","text_unique = list(np.unique(df['clean_text'].astype(str)))\n","\n","df_text = pd.DataFrame(text_unique, columns=['text'])\n","df_text = pd.concat([df_text, pd.DataFrame(list(range(len(text_unique))), columns=['numid'])], axis=1)\n","df_text.loc[:, \"text_id\"] = df_text[\"numid\"].astype(str).apply(lambda r: 'text_' + r)\n","df_text.iloc[:, [0, 2]].to_csv('textid.csv', mode='a', header=None, index=False, encoding = 'utf-8-sig')\n","print(f\"textid.csv has {df_text.shape[0]} rows\")"],"id":"Ba24GBRbJKKJ","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ukB4jSXpJTii"},"source":[""],"id":"ukB4jSXpJTii","execution_count":null,"outputs":[]}]}