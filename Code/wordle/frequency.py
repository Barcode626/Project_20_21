{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"frequency.py","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMl51NbkIP/Y44FOuoisAHx"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"BOCox5LtDHSE"},"source":["#!/usr/bin/env python\n","#\n","#  frequency.py\n","\"\"\"\n","Functions to determine word token frequency for wordclouds.\n",".. versionadded:: 0.2.0\n","\"\"\"\n","#\n","#  Copyright (c) 2020 Dominic Davis-Foster <dominic@davis-foster.co.uk>\n","#\n","#  Permission is hereby granted, free of charge, to any person obtaining a copy\n","#  of this software and associated documentation files (the \"Software\"), to deal\n","#  in the Software without restriction, including without limitation the rights\n","#  to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n","#  copies of the Software, and to permit persons to whom the Software is\n","#  furnished to do so, subject to the following conditions:\n","#\n","#  The above copyright notice and this permission notice shall be included in all\n","#  copies or substantial portions of the Software.\n","#\n","#  THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,\n","#  EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n","#  MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.\n","#  IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n","#  DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n","#  OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE\n","#  OR OTHER DEALINGS IN THE SOFTWARE.\n","#\n","\n","# stdlib\n","import pathlib\n","import re\n","import typing\n","from collections import Counter\n","from string import punctuation\n","from typing import Optional, Sequence\n","\n","# 3rd party\n","import pygments.lexers  # type: ignore\n","import pygments.token  # type: ignore\n","import pygments.util  # type: ignore\n","from domdf_python_tools.paths import PathPlus\n","from domdf_python_tools.typing import PathLike\n","\n","# this package\n","from wordle.utils import _TemporaryDirectory, clone_into_tmpdir\n","\n","__all__ = [\"frequency_from_directory\", \"frequency_from_file\", \"frequency_from_git\", \"get_tokens\"]\n","\n","\n","def get_tokens(filename: PathLike) -> typing.Counter[str]:\n","\t\"\"\"\n","\tReturns a :class:`collections.Counter` of the tokens in a file.\n","\t:param filename: The file to parse.\n","\t:return: A count of words etc. in the file.\n","\t\"\"\"\n","\n","\ttotal: typing.Counter[str] = Counter()\n","\n","\tfilename = PathPlus(filename)\n","\n","\ttry:\n","\t\tlex = pygments.lexers.get_lexer_for_filename(filename)\n","\texcept pygments.util.ClassNotFound:\n","\t\treturn total\n","\n","\tfor token in lex.get_tokens(filename.read_text()):\n","\t\tif token[0] in pygments.token.Comment:\n","\t\t\tcontinue\n","\n","\t\tif token[0] in pygments.token.Text:\n","\t\t\tif token[1] == '\\n':\n","\t\t\t\tcontinue\n","\t\t\tif token[1] == ' ':\n","\t\t\t\tcontinue\n","\t\t\tif re.match(r\"^\\t*$\", token[1]):\n","\t\t\t\tcontinue\n","\t\t\tif re.match(r\"^\\s*$\", token[1]):\n","\t\t\t\tcontinue\n","\n","\t\tif token[0] in pygments.token.String:\n","\t\t\tif token[1] == '\"':\n","\t\t\t\tcontinue\n","\n","\t\t\tif token[0] in pygments.token.String.Escape:\n","\t\t\t\tif re.match(r\"\\\\*\", token[1]):\n","\t\t\t\t\tcontinue\n","\n","\t\tif token[0] in pygments.token.String.Double:\n","\t\t\tif token[1] == '\\n':\n","\t\t\t\tcontinue\n","\t\t\tif re.match(r'^\"*$', token[1]):\n","\t\t\t\tcontinue\n","\n","\t\tif token[0] in pygments.token.String.Single:\n","\t\t\tif token[1] == '\\n':\n","\t\t\t\tcontinue\n","\t\t\tif re.match(r\"^'*$\", token[1]):\n","\t\t\t\tcontinue\n","\n","\t\tif token[0] in pygments.token.Punctuation and token[1] in \"[],{}:();\":\n","\t\t\tcontinue\n","\n","\t\tif token[0] in pygments.token.Operator:\n","\t\t\tcontinue\n","\n","\t\tif token[0] in pygments.token.String.Affix:\n","\t\t\tcontinue\n","\n","\t\tif token[0] in pygments.token.String.Interpol and token[1] in \"{}\":\n","\t\t\tcontinue\n","\n","\t\tif re.match(\"^:*$\", token[1]):\n","\t\t\tcontinue\n","\n","\t\ttotal += Counter(re.split(\"[ \\n\\t]\", token[1]))\n","\n","\tpunctuation_to_delete = ['', ' ']\n","\n","\tfor word in total:\n","\t\tif re.match(f\"^[{punctuation}]+$\", word):\n","\t\t\tpunctuation_to_delete.append(word)\n","\n","\tfor word in punctuation_to_delete:\n","\t\tdel total[word]\n","\n","\tall_words: typing.Counter[str] = Counter()\n","\n","\tfor word in total:\n","\t\tif word.endswith(':'):\n","\t\t\tall_words[word.rstrip(':')] = total[word]\n","\t\telse:\n","\t\t\tall_words[word] = total[word]\n","\n","\treturn all_words\n","\n","\n","def frequency_from_file(\n","\t\tfilename: PathLike,\n","\t\texclude_words: Sequence[str] = (),\n","\t\t) -> Counter:\n","\t\"\"\"\n","\tReturns a dictionary mapping the words in the file to their frequencies.\n","\t:param filename: The file to process\n","\t:param exclude_words: An optional list of words to exclude\n","\t.. versionadded:: 0.2.0\n","\t.. seealso:: func:`~.get_tokens`\n","\t\"\"\"\n","\n","\tword_counts = get_tokens(filename)\n","\n","\tfor word in exclude_words:\n","\t\tif word in word_counts:\n","\t\t\tdel word_counts[word]\n","\n","\treturn word_counts\n","\n","\n","def frequency_from_directory(\n","\t\tdirectory: PathLike,\n","\t\texclude_words: Sequence[str] = (),\n","\t\texclude_dirs: Sequence[PathLike] = (),\n","\t\t) -> Counter:\n","\t\"\"\"\n","\tReturns a dictionary mapping the words in files in ``directory`` to their frequencies.\n","\t:param directory: The directory to process\n","\t:param exclude_words: An optional list of words to exclude\n","\t:param exclude_dirs: An optional list of directories to exclude.\n","\t.. versionadded:: 0.2.0\n","\t\"\"\"\n","\n","\t# TODO: only certain file extensions\n","\n","\tdirectory = pathlib.Path(directory).absolute()\n","\n","\texclude_dirs_list = [\".git\"]\n","\n","\tfor d in exclude_dirs:\n","\t\td = pathlib.Path(d)\n","\n","\t\tif d.is_absolute():\n","\t\t\td = d.relative_to(directory)\n","\n","\t\texclude_dirs_list.append(str(d))\n","\n","\tdef is_excluded(path):\n","\t\tfor dir_name in exclude_dirs_list:\n","\t\t\tif re.match(dir_name, path.relative_to(directory).as_posix()):\n","\t\t\t\treturn True\n","\t\treturn False\n","\n","\tword_counts: typing.Counter[str] = Counter()\n","\n","\tfor file in directory.rglob(\"**/*.*\"):\n","\t\tif file.is_file() and not is_excluded(file):\n","\t\t\tword_counts += get_tokens(file)\n","\n","\tfor word in exclude_words:\n","\t\tif word in word_counts:\n","\t\t\tdel word_counts[word]\n","\n","\treturn word_counts\n","\n","\n","def frequency_from_git(\n","\t\tgit_url: str,\n","\t\tsha: Optional[str] = None,\n","\t\tdepth: Optional[int] = None,\n","\t\texclude_words: Sequence[str] = (),\n","\t\texclude_dirs: Sequence[PathLike] = (),\n","\t\t) -> Counter:\n","\t\"\"\"\n","\tReturns a dictionary mapping the words in files in ``directory`` to their frequencies.\n","\t:param git_url: The url of the git repository to process\n","\t:param sha: An optional SHA hash of a commit to checkout.\n","\t:param depth: An optional depth to clone at. If :py:obj:`None` and ``sha`` is :py:obj:`None` the depth is ``1``.\n","\t\tIf :py:obj:`None` and ``sha`` is given the depth is unlimited.\n","\t:param exclude_words: An optional list of words to exclude.\n","\t:param exclude_dirs: An optional list of directories to exclude.\n","\t.. versionadded:: 0.2.0\n","\t\"\"\"\n","\n","\twith _TemporaryDirectory() as tmpdir:\n","\t\tclone_into_tmpdir(git_url, tmpdir, sha=sha, depth=depth)\n","\n","\t\treturn frequency_from_directory(\n","\t\t\t\ttmpdir,\n","\t\t\t\texclude_dirs=exclude_dirs,\n","\t\t\t\texclude_words=exclude_words,\n","\t\t\t\t)"],"execution_count":null,"outputs":[]}]}