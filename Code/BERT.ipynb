{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"6_BERT.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"6eU97gtr5-rw"},"source":["import os\n","import numpy as np\n","import pandas as pd\n","import csv\n","import time\n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n","os.chdir(\"/content/drive/MyDrive/Data\")\n","\n","!pip install transformers\n","from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"inWMUA3f6cPv"},"source":["model_name = \"distilbert-base-uncased-finetuned-sst-2-english\"\n","pt_model = AutoModelForSequenceClassification.from_pretrained(model_name)\n","tokenizer = AutoTokenizer.from_pretrained(model_name)\n","classifier = pipeline('sentiment-analysis', model=pt_model, tokenizer=tokenizer)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"17vfpuOf6dYJ"},"source":["def get_senti_labels(content):\n","    result = classifier(content)[0]\n","    if result['label'] == \"NEGATIVE\":\n","        label = 0\n","    else:\n","        label = 1\n","    return label, round(result['score'], 4)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"C7yrFrc06qsf"},"source":["df_chunk = pd.read_csv('textid.csv', header = None, dtype = str, \\\n","                                            chunksize=300000, encoding = 'utf-8-sig', engine='python')\n","file_counts = 0\n","for chunk in df_chunk:\n","    chunk_time = time.time()\n","    chunk.columns = ['text', 'text_id']\n","    chunk.dropna(subset=[\"text_id\"], axis=0, how='any', inplace=True)\n","    chunk.dropna(subset=['text'], axis=0, how='any', inplace=True)\n","    \n","    chunk.loc[:, \"st_labels\"] = chunk[\"text\"].astype(str).apply(lambda r: get_senti_labels(r)[0])\n","    chunk.loc[:, \"st_scores\"] = chunk[\"text\"].astype(str).apply(lambda r: get_senti_labels(r)[1])\n","\n","    chunk.to_csv('textid_st.csv', mode='a', header=None, index=False, encoding = 'utf-8-sig') \n","    \n","    file_counts += 1\n","    print(f\"File {file_counts}:\")\n","    print(f\"- cost time: {(time.time() - chunk_time)//60} minutes\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"quf4GhV6i5Nl"},"source":[""],"execution_count":null,"outputs":[]}]}